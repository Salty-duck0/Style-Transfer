{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-25T12:27:35.263358Z","iopub.execute_input":"2023-06-25T12:27:35.263714Z","iopub.status.idle":"2023-06-25T12:27:35.274940Z","shell.execute_reply.started":"2023-06-25T12:27:35.263684Z","shell.execute_reply":"2023-06-25T12:27:35.273882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!pip install tensorflow==2.12\n#!pip install protobuf==4.23.3\n#!pip install tensorflow-addons==0.19.0","metadata":{"execution":{"iopub.status.busy":"2023-06-25T12:27:35.277712Z","iopub.execute_input":"2023-06-25T12:27:35.278164Z","iopub.status.idle":"2023-06-25T12:27:35.283999Z","shell.execute_reply.started":"2023-06-25T12:27:35.278128Z","shell.execute_reply":"2023-06-25T12:27:35.283082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Conv2D,LeakyReLU,Conv2DTranspose,Dropout,Concatenate,Input,ZeroPadding2D\nimport os\nimport numpy as np\nfrom PIL import Image\nfrom tqdm import tqdm\nimport time\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow_addons as tfa\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2023-06-25T12:27:35.288111Z","iopub.execute_input":"2023-06-25T12:27:35.288375Z","iopub.status.idle":"2023-06-25T12:27:35.295775Z","shell.execute_reply.started":"2023-06-25T12:27:35.288353Z","shell.execute_reply":"2023-06-25T12:27:35.294950Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE = 256\nIMAGE_CHANNELS = 3 #all images have same size\n\nOTHER_BATCH = 2\n\nPREVIEW_ROWS = 4\nPREVIEW_COLS = 7\nPREVIEW_MARGIN = 16\n\nBATCH_SIZE = 32\nBUFFER_SIZE = 60000\nAUTOTUNE = tf.data.experimental.AUTOTUNE\nDATA_PATH = '/kaggle/input/monet-data'","metadata":{"execution":{"iopub.status.busy":"2023-06-25T12:27:35.303815Z","iopub.execute_input":"2023-06-25T12:27:35.304752Z","iopub.status.idle":"2023-06-25T12:27:35.310888Z","shell.execute_reply.started":"2023-06-25T12:27:35.304728Z","shell.execute_reply":"2023-06-25T12:27:35.310048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def hms_string(sec_elapsed):\n    \"\"\"\n    This function is give us seconds in a formatted manner\n    \"\"\"\n    h = int(sec_elapsed / (60 * 60))\n    m = int((sec_elapsed % (60 * 60)) / 60)\n    s = sec_elapsed % 60\n    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)","metadata":{"execution":{"iopub.status.busy":"2023-06-25T12:27:35.315093Z","iopub.execute_input":"2023-06-25T12:27:35.315340Z","iopub.status.idle":"2023-06-25T12:27:35.321680Z","shell.execute_reply.started":"2023-06-25T12:27:35.315319Z","shell.execute_reply":"2023-06-25T12:27:35.320544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"monet_filenames = tf.io.gfile.glob(str(DATA_PATH + '/monet_tfrec/*.tfrec'))\nphoto_filenames = tf.io.gfile.glob(str(DATA_PATH + '/photo_tfrec/*.tfrec'))","metadata":{"execution":{"iopub.status.busy":"2023-06-25T12:27:35.324512Z","iopub.execute_input":"2023-06-25T12:27:35.325113Z","iopub.status.idle":"2023-06-25T12:27:35.346210Z","shell.execute_reply.started":"2023-06-25T12:27:35.325083Z","shell.execute_reply":"2023-06-25T12:27:35.345370Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = {'image': tf.io.FixedLenFeature([], tf.string)}\n\ndef read_tfrecord(example):\n    image_data = tf.io.parse_single_example(example, features)\n    image = image_data['image']\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = (tf.cast(image, tf.float32) / 127.5) - 1\n    image = tf.reshape(image, [IMAGE_SIZE,IMAGE_SIZE, 3])\n    return image\n\n\nmonet_dataset = tf.data.TFRecordDataset(monet_filenames).map(read_tfrecord, num_parallel_calls=AUTOTUNE).batch(1)\nphoto_dataset = tf.data.TFRecordDataset(photo_filenames).map(read_tfrecord, num_parallel_calls=AUTOTUNE).batch(1)","metadata":{"execution":{"iopub.status.busy":"2023-06-25T12:27:35.347788Z","iopub.execute_input":"2023-06-25T12:27:35.348106Z","iopub.status.idle":"2023-06-25T12:27:35.404166Z","shell.execute_reply.started":"2023-06-25T12:27:35.348077Z","shell.execute_reply":"2023-06-25T12:27:35.403307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def downsample(filters, size, apply_instancenorm=True):\n    initializer = tf.random_normal_initializer(0., 0.02)\n    gamma_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n\n    result = keras.Sequential()\n    result.add(Conv2D(filters, size, strides=2, padding='same',kernel_initializer=initializer, use_bias=False))\n\n    if apply_instancenorm:\n        result.add(tfa.layers.InstanceNormalization(gamma_initializer=gamma_init))\n\n    result.add(LeakyReLU())\n\n    return result","metadata":{"execution":{"iopub.status.busy":"2023-06-25T12:27:35.405777Z","iopub.execute_input":"2023-06-25T12:27:35.406193Z","iopub.status.idle":"2023-06-25T12:27:35.412713Z","shell.execute_reply.started":"2023-06-25T12:27:35.406161Z","shell.execute_reply":"2023-06-25T12:27:35.411484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def upsample(filters, size, apply_dropout=False):\n    initializer = tf.random_normal_initializer(0., 0.02)\n    gamma_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n\n    result = keras.Sequential()\n    result.add(Conv2DTranspose(filters, size, strides=2,padding='same',kernel_initializer=initializer,use_bias=False))\n\n    result.add(tfa.layers.InstanceNormalization(gamma_initializer=gamma_init))\n\n    if apply_dropout:\n        result.add(Dropout(0.3))\n\n    result.add(LeakyReLU())\n\n    return result","metadata":{"execution":{"iopub.status.busy":"2023-06-25T12:27:35.416298Z","iopub.execute_input":"2023-06-25T12:27:35.416688Z","iopub.status.idle":"2023-06-25T12:27:35.426967Z","shell.execute_reply.started":"2023-06-25T12:27:35.416598Z","shell.execute_reply":"2023-06-25T12:27:35.425971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Generator():\n    inputs = Input(shape=[256,256,3])\n\n\n    down_stack = [\n        downsample(64, 4, apply_instancenorm=False),\n        downsample(128, 4),\n        downsample(256, 4),\n        downsample(512, 4),\n        downsample(512, 4),\n        downsample(512, 4),\n        downsample(512, 4),\n        downsample(512, 4),\n    ]\n\n    up_stack = [\n        upsample(512, 4, apply_dropout=True),\n        upsample(512, 4, apply_dropout=True),\n        upsample(512, 4, apply_dropout=True),\n        upsample(512, 4),\n        upsample(256, 4),\n        upsample(128, 4),\n        upsample(64, 4),\n    ]\n    initializer = tf.random_normal_initializer(0., 0.02)\n    last = Conv2DTranspose(IMAGE_CHANNELS, 4,\n                                  strides=2,\n                                  padding='same',\n                                  kernel_initializer=initializer,\n                                  activation='tanh')\n    x = inputs\n\n\n    skips = []\n    for down in down_stack:\n        x = down(x)\n        skips.append(x)\n\n    skips = reversed(skips[:-1])\n\n\n    for up, skip in zip(up_stack, skips):\n        x = up(x)\n        x = Concatenate()([x, skip])\n\n    x = last(x)\n\n    return keras.Model(inputs=inputs, outputs=x)","metadata":{"execution":{"iopub.status.busy":"2023-06-25T12:27:35.428433Z","iopub.execute_input":"2023-06-25T12:27:35.428780Z","iopub.status.idle":"2023-06-25T12:27:35.440670Z","shell.execute_reply.started":"2023-06-25T12:27:35.428750Z","shell.execute_reply":"2023-06-25T12:27:35.439632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Discriminator():\n    initializer = tf.random_normal_initializer(0., 0.02)\n    gamma_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n\n    input = Input(shape=[256, 256, 3])\n\n    x = input\n\n    x = downsample(64, 4, False)(x)\n    x = downsample(128, 4)(x)\n    x = downsample(256, 4)(x)\n\n    zero_pad1 = ZeroPadding2D()(x)\n    conv = Conv2D(512, 4, strides=1,\n                         kernel_initializer=initializer,\n                         use_bias=False)(zero_pad1)\n\n    norm1 = tfa.layers.InstanceNormalization(gamma_initializer=gamma_init)(conv)\n\n    leaky_relu = LeakyReLU()(norm1)\n\n    zero_pad2 = ZeroPadding2D()(leaky_relu)\n\n    last = Conv2D(1, 4, strides=1,\n                         kernel_initializer=initializer)(zero_pad2)\n\n    return tf.keras.Model(inputs=input, outputs=last)","metadata":{"execution":{"iopub.status.busy":"2023-06-25T12:27:35.441972Z","iopub.execute_input":"2023-06-25T12:27:35.442368Z","iopub.status.idle":"2023-06-25T12:27:35.454114Z","shell.execute_reply.started":"2023-06-25T12:27:35.442338Z","shell.execute_reply":"2023-06-25T12:27:35.453131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"monet_generator = Generator()\nphoto_generator = Generator()\nmonet_discriminator = Discriminator()\nphoto_discriminator = Discriminator()","metadata":{"execution":{"iopub.status.busy":"2023-06-25T12:27:35.455702Z","iopub.execute_input":"2023-06-25T12:27:35.456094Z","iopub.status.idle":"2023-06-25T12:27:38.056689Z","shell.execute_reply.started":"2023-06-25T12:27:35.456064Z","shell.execute_reply":"2023-06-25T12:27:38.055718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def discriminator_loss(real, generated):\n    real_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(tf.ones_like(real), real)\n    generated_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(tf.zeros_like(generated), generated)\n    total_disc_loss = real_loss + generated_loss\n    return total_disc_loss * 0.5","metadata":{"execution":{"iopub.status.busy":"2023-06-25T12:27:38.058056Z","iopub.execute_input":"2023-06-25T12:27:38.058400Z","iopub.status.idle":"2023-06-25T12:27:38.064688Z","shell.execute_reply.started":"2023-06-25T12:27:38.058368Z","shell.execute_reply":"2023-06-25T12:27:38.063852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generator_loss(generated):\n    return tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(tf.ones_like(generated), generated)","metadata":{"execution":{"iopub.status.busy":"2023-06-25T12:27:38.066076Z","iopub.execute_input":"2023-06-25T12:27:38.067072Z","iopub.status.idle":"2023-06-25T12:27:38.074957Z","shell.execute_reply.started":"2023-06-25T12:27:38.067040Z","shell.execute_reply":"2023-06-25T12:27:38.074005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calc_cycle_loss(real_image, cycled_image, LAMBDA):\n    loss1 = tf.reduce_mean(tf.abs(real_image - cycled_image))\n    return LAMBDA * loss1","metadata":{"execution":{"iopub.status.busy":"2023-06-25T12:27:38.078762Z","iopub.execute_input":"2023-06-25T12:27:38.079066Z","iopub.status.idle":"2023-06-25T12:27:38.085836Z","shell.execute_reply.started":"2023-06-25T12:27:38.079044Z","shell.execute_reply":"2023-06-25T12:27:38.084742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def identity_loss(real_image, same_image, LAMBDA):\n    loss = tf.reduce_mean(tf.abs(real_image - same_image))\n    return LAMBDA * 0.5 * loss","metadata":{"execution":{"iopub.status.busy":"2023-06-25T12:27:38.087631Z","iopub.execute_input":"2023-06-25T12:27:38.087973Z","iopub.status.idle":"2023-06-25T12:27:38.096714Z","shell.execute_reply.started":"2023-06-25T12:27:38.087943Z","shell.execute_reply":"2023-06-25T12:27:38.095660Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"monet_generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\nphoto_generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\nmonet_discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\nphoto_discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)","metadata":{"execution":{"iopub.status.busy":"2023-06-25T12:27:38.097910Z","iopub.execute_input":"2023-06-25T12:27:38.098344Z","iopub.status.idle":"2023-06-25T12:27:38.113046Z","shell.execute_reply.started":"2023-06-25T12:27:38.098259Z","shell.execute_reply":"2023-06-25T12:27:38.112083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CycleGan(keras.Model):\n    def __init__(\n        self,\n        monet_generator,\n        photo_generator,\n        monet_discriminator,\n        photo_discriminator,\n        lambda_cycle=10,\n    ):\n        super(CycleGan, self).__init__()\n        self.m_gen = monet_generator\n        self.p_gen = photo_generator\n        self.m_disc = monet_discriminator\n        self.p_disc = photo_discriminator\n        self.lambda_cycle = lambda_cycle\n\n    def compile(\n        self,\n        m_gen_optimizer,\n        p_gen_optimizer,\n        m_disc_optimizer,\n        p_disc_optimizer,\n        gen_loss_fn,\n        disc_loss_fn,\n        cycle_loss_fn,\n        identity_loss_fn\n    ):\n        super(CycleGan, self).compile()\n        self.m_gen_optimizer = m_gen_optimizer\n        self.p_gen_optimizer = p_gen_optimizer\n        self.m_disc_optimizer = m_disc_optimizer\n        self.p_disc_optimizer = p_disc_optimizer\n        self.gen_loss_fn = gen_loss_fn\n        self.disc_loss_fn = disc_loss_fn\n        self.cycle_loss_fn = cycle_loss_fn\n        self.identity_loss_fn = identity_loss_fn\n\n    def train_step(self, batch_data):\n        real_monet, real_photo = batch_data\n\n        with tf.GradientTape(persistent=True) as tape:\n\n            fake_monet = self.m_gen(real_photo, training=True)\n            cycled_photo = self.p_gen(fake_monet, training=True)\n\n\n            fake_photo = self.p_gen(real_monet, training=True)\n            cycled_monet = self.m_gen(fake_photo, training=True)\n\n\n            same_monet = self.m_gen(real_monet, training=True)\n            same_photo = self.p_gen(real_photo, training=True)\n\n\n            disc_real_monet = self.m_disc(real_monet, training=True)\n            disc_real_photo = self.p_disc(real_photo, training=True)\n\n\n            disc_fake_monet = self.m_disc(fake_monet, training=True)\n            disc_fake_photo = self.p_disc(fake_photo, training=True)\n\n\n            monet_gen_loss = self.gen_loss_fn(disc_fake_monet)\n            photo_gen_loss = self.gen_loss_fn(disc_fake_photo)\n\n\n            total_cycle_loss = self.cycle_loss_fn(real_monet, cycled_monet, self.lambda_cycle) + self.cycle_loss_fn(real_photo, cycled_photo, self.lambda_cycle)\n\n\n            total_monet_gen_loss = monet_gen_loss + total_cycle_loss + self.identity_loss_fn(real_monet, same_monet, self.lambda_cycle)\n            total_photo_gen_loss = photo_gen_loss + total_cycle_loss + self.identity_loss_fn(real_photo, same_photo, self.lambda_cycle)\n\n\n            monet_disc_loss = self.disc_loss_fn(disc_real_monet, disc_fake_monet)\n            photo_disc_loss = self.disc_loss_fn(disc_real_photo, disc_fake_photo)\n\n\n        monet_generator_gradients = tape.gradient(total_monet_gen_loss,self.m_gen.trainable_variables)\n        photo_generator_gradients = tape.gradient(total_photo_gen_loss,self.p_gen.trainable_variables)\n\n        monet_discriminator_gradients = tape.gradient(monet_disc_loss,self.m_disc.trainable_variables)\n        photo_discriminator_gradients = tape.gradient(photo_disc_loss,self.p_disc.trainable_variables)\n\n\n        self.m_gen_optimizer.apply_gradients(zip(monet_generator_gradients,self.m_gen.trainable_variables))\n\n        self.p_gen_optimizer.apply_gradients(zip(photo_generator_gradients,self.p_gen.trainable_variables))\n\n        self.m_disc_optimizer.apply_gradients(zip(monet_discriminator_gradients,self.m_disc.trainable_variables))\n\n        self.p_disc_optimizer.apply_gradients(zip(photo_discriminator_gradients,self.p_disc.trainable_variables))\n\n        return {\n            \"monet_gen_loss\": total_monet_gen_loss,\n            \"photo_gen_loss\": total_photo_gen_loss,\n            \"monet_disc_loss\": monet_disc_loss,\n            \"photo_disc_loss\": photo_disc_loss\n        }","metadata":{"execution":{"iopub.status.busy":"2023-06-25T12:27:38.115993Z","iopub.execute_input":"2023-06-25T12:27:38.116654Z","iopub.status.idle":"2023-06-25T12:27:38.134129Z","shell.execute_reply.started":"2023-06-25T12:27:38.116623Z","shell.execute_reply":"2023-06-25T12:27:38.133021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cycle_gan_model = CycleGan(\n        monet_generator, photo_generator, monet_discriminator, photo_discriminator\n)\n\ncycle_gan_model.compile(\n        m_gen_optimizer = monet_generator_optimizer,\n        p_gen_optimizer = photo_generator_optimizer,\n        m_disc_optimizer = monet_discriminator_optimizer,\n        p_disc_optimizer = photo_discriminator_optimizer,\n        gen_loss_fn = generator_loss,\n        disc_loss_fn = discriminator_loss,\n        cycle_loss_fn = calc_cycle_loss,\n        identity_loss_fn = identity_loss\n)","metadata":{"execution":{"iopub.status.busy":"2023-06-25T12:27:38.135370Z","iopub.execute_input":"2023-06-25T12:27:38.135883Z","iopub.status.idle":"2023-06-25T12:27:38.162034Z","shell.execute_reply.started":"2023-06-25T12:27:38.135852Z","shell.execute_reply":"2023-06-25T12:27:38.160993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_path = '/kaggle/working/ckpt'\n\nckpt = tf.train.Checkpoint(monet_generator=monet_generator,\n                           photo_generator=photo_generator,\n                           monet_discriminator=monet_discriminator,\n                           photo_discriminator=photo_discriminator,\n                           monet_generator_optimizer=monet_generator_optimizer,\n                           photo_generator_optimizer=photo_generator_optimizer,\n                           monet_discriminator_optimizer=monet_discriminator_optimizer,\n                           photo_discriminator_optimizer=photo_discriminator_optimizer)","metadata":{"execution":{"iopub.status.busy":"2023-06-25T12:27:38.163182Z","iopub.execute_input":"2023-06-25T12:27:38.163572Z","iopub.status.idle":"2023-06-25T12:27:38.171174Z","shell.execute_reply.started":"2023-06-25T12:27:38.163541Z","shell.execute_reply":"2023-06-25T12:27:38.169364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ckpt.restore(tf.train.latest_checkpoint(checkpoint_path))","metadata":{"execution":{"iopub.status.busy":"2023-06-25T13:09:02.642015Z","iopub.execute_input":"2023-06-25T13:09:02.642368Z","iopub.status.idle":"2023-06-25T13:09:02.649572Z","shell.execute_reply.started":"2023-06-25T13:09:02.642339Z","shell.execute_reply":"2023-06-25T13:09:02.648548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cycle_gan_model.fit(\n    tf.data.Dataset.zip((monet_dataset.repeat(-1), photo_dataset.repeat(-1))),\n    steps_per_epoch=300,\n    epochs=300\n)\nckpt.save(file_prefix = checkpoint_path)","metadata":{"execution":{"iopub.status.busy":"2023-06-25T13:09:07.235561Z","iopub.execute_input":"2023-06-25T13:09:07.235946Z","iopub.status.idle":"2023-06-25T13:09:37.489138Z","shell.execute_reply.started":"2023-06-25T13:09:07.235914Z","shell.execute_reply":"2023-06-25T13:09:37.487209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_, ax = plt.subplots(2, 2, figsize=(12, 12))\nfor i, img in enumerate(photo_dataset.take(2)):\n    prediction = monet_generator(img, training=False)[0].numpy()\n    prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n    img = (img[0] * 127.5 + 127.5).numpy().astype(np.uint8)\n\n    ax[i, 0].imshow(img)\n    ax[i, 1].imshow(prediction)\n    ax[i, 0].set_title(\"Input Photo\")\n    ax[i, 1].set_title(\"Monet-esque\")\n    ax[i, 0].axis(\"off\")\n    ax[i, 1].axis(\"off\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-06-25T13:07:33.224599Z","iopub.execute_input":"2023-06-25T13:07:33.225190Z","iopub.status.idle":"2023-06-25T13:07:34.620882Z","shell.execute_reply.started":"2023-06-25T13:07:33.225155Z","shell.execute_reply":"2023-06-25T13:07:34.619737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}